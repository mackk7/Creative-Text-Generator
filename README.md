# Creative Text Generator ‚Äî End-to-End NLP Project (PyTorch & Streamlit)

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://creative-text-generator-zu6p6wmqnffrcxkbjamazk.streamlit.app/)
[![GitHub Repo](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/mackk7/Creative-Text-Generator.git)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)



A deployed deep learning application demonstrating creative text generation using PyTorch LSTMs, trained on a large, diverse corpus (1.5M sequences from song lyrics & news headlines) and served via an interactive Streamlit UI.
This project showcases the full lifecycle from data engineering and model training to deployment, including professional handling of large model files (>100MB) without Git LFS.

## üöÄ Live Demo

Interact with the deployed app here:
‚û°Ô∏è (https://creative-text-generator-zu6p6wmqnffrcxkbjamazk.streamlit.app/)

üñºÔ∏è Preview

Screenshot of the Streamlit interface
<img width="1851" height="955" alt="Screenshot 2025-10-21 154229" src="https://github.com/user-attachments/assets/3eef7332-079b-4bc0-8343-b507cf73b9af" />


Example Output (Top-K Sampling, k=3, T=0.8):

Seed: The city sleeps but
Generated: the city sleeps but i know that i'm not alone...

## üéØ Project Objective & Core Achievements

This project demonstrates proficiency in building and deploying a non-trivial NLP system, focusing on:

* ‚úÖ **End-to-End Pipeline Construction:** Successfully managing the entire workflow from raw data ingestion (`.csv` files) and **memory-efficient preprocessing** to model training (PyTorch LSTM), artifact management, and deployment (Streamlit).

* ‚úÖ **Large-Scale Data Handling:** Engineering a data pipeline capable of processing a **>50M token corpus** within constrained cloud environments (Kaggle) by implementing sequential file loading and explicit garbage collection (`gc.collect()`).

* ‚úÖ **Deep Learning Model Training:** Training a 2-layer LSTM network (`hidden_size=512`) on a substantial data sample (**1.5M sequences**) to learn language patterns, achieving a final training loss of **3.2290** within a realistic timeframe (~2 hours on GPU).

* ‚úÖ **Professional Artifact Management:** **Critically bypassing Git LFS limitations** for the >100MB model file (`.pth`). Implemented a robust `.gitignore` strategy combined with external hosting (Google Drive/Dropbox) and on-demand downloading within the Streamlit application. This ensures a **lean, functional Git repository** suitable for CI/CD and collaboration, explicitly avoiding LFS pointer file issues.

* ‚úÖ **Interactive Application Development:** Creating a responsive and aesthetically refined user interface using Streamlit, featuring custom CSS (dark neumorphic theme) for enhanced UX and conditional logic for displaying model metrics.

---

## üõ†Ô∏è Architecture & Workflow

The deployed application follows this inference workflow:

```
graph LR
    A[User Input (Text)] --> B(Streamlit UI - app.py);
    B --> C{Preprocessing (Tokenization w/ vocab_objects.pth)};
    C --> D[PyTorch LSTM Model (model.py)];
    subgraph Model Loading
        direction LR
        D -- Loads Weights --> E(creative_text_generator.pth);
        F{Downloads if Missing} -- From Cloud URL --> E;
    end
    D --> G{Postprocessing (Top-K Sampling)};
    G --> H[Generated Text];
    H --> B;
```

Frontend: Streamlit (app.py) handles UI and orchestrates calls.

Model Definition: A separate model.py contains the PyTorch LSTM class definition for modularity.

Vocabulary: Pre-computed mappings (vocab_objects.pth, ~1-2MB) generated by preprocess.py are included in the repo for fast startup.

Model Weights: The large .pth file (>100MB) is hosted externally and downloaded/cached by app.py, keeping the Git repo small and deployable.


üß© Components

Frontend: Streamlit (UI + input handling)

Model: PyTorch 2-layer LSTM (in model.py)

Vocab: Precomputed vocab_objects.pth

Weights: creative_text_generator.pth hosted externally (e.g., Google Drive)

‚öôÔ∏è Local Setup
1. Clone Repository
git clone (https://github.com/mackk7/Creative-Text-Generator.git)
cd creative-text-generator

2. Create Environment
python -m venv venv
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

pip install -r requirements.txt
python -m nltk.downloader punkt

3. Prepare Data (Run Once)

Download:

lyrics-data.csv

abcnews-date-text.csv

Then run:

python preprocess.py

4. Configure Model URL

Edit app.py ‚Üí find MODEL_URL = ""
https://www.dropbox.com/scl/fi/may99yg8hro9571prwlv8/creative_text_generator.pth?rlkey=4xft0gnpgq68r8bbietfpjtal&st=d98r0pak&dl=1

5. Run the App
streamlit run app.py


Your model will auto-download and cache on first run.

üß† Model Details
Parameter	Value
Layers	2
Hidden Size	512
Embedding	256
Dropout	0.5
Sampling	Top-K (k=3), Temperature=0.8
Corpus	Lyrics + News (1.5M sequences)

üë®‚Äçüíª Developed By

---

*Developed by Mayank [![GitHub Profile](https://img.shields.io/badge/GitHub-mackk7-blue?logo=github&style=flat)](https://github.com/mackk7)*

Project built with ‚ù§Ô∏è using PyTorch & Streamlit




